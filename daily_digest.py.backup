#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
daily_digest.py (patched)
- Adiciona sanitiza√ß√£o do ICS para corrigir "unsupported property: 02"
- Expans√£o de RRULE no iCal
- Fallback Google Calendar API
- Slack DMs com resolu√ß√£o por @handle, display_name, real_name, email e IDs diretos
- Flag opcional --slack-dump para listar usu√°rios detectados
"""

import argparse
import datetime as dt
import json
import os
import re
import sys
import time
from urllib.parse import quote
from zoneinfo import ZoneInfo

import requests

try:
    from dotenv import load_dotenv

    load_dotenv()
except Exception:
    pass

TZ = ZoneInfo(os.getenv("TIMEZONE", "America/Sao_Paulo"))


# ---------- Helpers ----------
def h2(t):
    return f"\n{t}\n" + "‚Äî" * len(t) + "\n"


def to_iso_z(d):
    return d.astimezone(ZoneInfo("UTC")).isoformat()


def env_required(name):
    v = os.getenv(name)
    if not v:
        print(f"[aviso] vari√°vel {name} n√£o definida; pulando esta fonte.")
    return v


# ---------- Slack token store/refresh ----------
def _store_path():
    return os.getenv("SLACK_TOKEN_STORE", ".slack_token.json")


def _load_store():
    if os.path.exists(_store_path()):
        try:
            with open(_store_path(), "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def _save_store(data):
    try:
        with open(_store_path(), "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2)
    except:
        pass


def get_slack_access_token():
    if os.getenv("SLACK_USER_TOKEN"):
        return os.getenv("SLACK_USER_TOKEN"), "env"
    store = _load_store()
    now = int(time.time())
    if store.get("access_token") and store.get("expires_at", 0) > now + 60:
        return store["access_token"], "store"
    cid = env_required("SLACK_CLIENT_ID")
    csec = env_required("SLACK_CLIENT_SECRET")
    rtok = store.get("refresh_token") or os.getenv("SLACK_REFRESH_TOKEN")
    if not (cid and csec and rtok):
        return None, "missing"
    url = "https://slack.com/api/oauth.v2.access"
    resp = requests.post(
        url,
        data={
            "client_id": cid,
            "client_secret": csec,
            "grant_type": "refresh_token",
            "refresh_token": rtok,
        },
        timeout=30,
    ).json()
    if not resp.get("ok"):
        return None, "refresh-failed"
    atok = resp.get("access_token") or resp.get("token")
    new_r = resp.get("refresh_token") or rtok
    exp_in = int(resp.get("expires_in", 12 * 60 * 60))
    _save_store(
        {
            "access_token": atok,
            "refresh_token": new_r,
            "expires_at": int(time.time()) + exp_in,
        }
    )
    return atok, "refreshed"


def _slack_user_map(headers):
    users = {}
    cursor = None
    while True:
        params = {"limit": 200}
        if cursor:
            params["cursor"] = cursor
        res = requests.get(
            "https://slack.com/api/users.list",
            headers=headers,
            params=params,
            timeout=30,
        ).json()
        if not res.get("ok"):
            break
        for m in res.get("members", []):
            uid = m.get("id")
            name = m.get("name") or ""
            prof = m.get("profile", {}) or {}
            disp = prof.get("display_name_normalized") or ""
            real = prof.get("real_name_normalized") or ""
            email = prof.get("email")
            if name:
                users["@" + name.lower()] = uid
            if disp:
                users["@" + disp.lower()] = uid
            if real:
                users["@" + real.lower()] = uid
            if email:
                users[email.lower()] = uid
        cursor = res.get("response_metadata", {}).get("next_cursor")
        if not cursor:
            break
    return users


def slack_dump():
    atok, _ = get_slack_access_token()
    if not atok:
        return 1
    headers = {"Authorization": f"Bearer {atok}"}
    m = _slack_user_map(headers)
    print(json.dumps(m, indent=2, ensure_ascii=False))
    return 0


def slack_dm_huddles(START, END):
    atok, _ = get_slack_access_token()
    if not atok:
        return []
    headers = {"Authorization": f"Bearer {atok}"}

    usernames = [
        u.strip() for u in os.getenv("SLACK_DM_USERNAMES", "").split(",") if u.strip()
    ]
    emails = [
        e.strip().lower()
        for e in os.getenv("SLACK_DM_EMAILS", "").split(",")
        if e.strip()
    ]
    ids = [
        i.strip() for i in os.getenv("SLACK_DM_USER_IDS", "").split(",") if i.strip()
    ]

    users = _slack_user_map(headers)
    # email lookup extra
    for em in emails:
        if em in users:
            continue
        lr = requests.get(
            "https://slack.com/api/users.lookupByEmail",
            headers=headers,
            params={"email": em},
            timeout=15,
        ).json()
        if lr.get("ok"):
            uid = lr.get("user", {}).get("id")
            if uid:
                users[em] = uid

    target_ids = []
    for uname in usernames:
        uid = users.get(uname.lower())
        if uid:
            target_ids.append(uid)
        else:
            print(f"[aviso] Slack: n√£o achei {uname}")
    for em in emails:
        uid = users.get(em)
        if uid:
            target_ids.append(uid)
        else:
            print(f"[aviso] Slack: n√£o achei {em}")
    target_ids += ids

    # abrir DMs
    dm_ids = []
    for uid in target_ids:
        opened = requests.post(
            "https://slack.com/api/conversations.open",
            headers=headers,
            data={"users": uid},
            timeout=15,
        ).json()
        if opened.get("ok") and opened.get("channel", {}).get("id"):
            dm_ids.append(opened["channel"]["id"])

    # hist√≥rico
    rx = re.compile(
        "|".join(
            [
                r"\biniciou um huddle\b",
                r"\bhuddle iniciado\b",
                r"\bstarted a huddle\b",
                r"\bjoined the huddle\b",
                r"\bhuddle ended\b",
            ]
        ),
        re.IGNORECASE,
    )
    out = []
    for dm in dm_ids:
        hist = requests.get(
            "https://slack.com/api/conversations.history",
            headers=headers,
            params={
                "channel": dm,
                "oldest": int(START.timestamp()),
                "latest": int(END.timestamp()),
            },
            timeout=30,
        ).json()
        for msg in hist.get("messages", []):
            if "huddle" in (msg.get("subtype") or "") or rx.search(msg.get("text", "")):
                out.append(msg)
    return out


# ---------- ICS sanitizer ----------
def _sanitize_ics(raw: bytes) -> bytes:
    # Normalize line endings
    txt = raw.replace(b"\r\n", b"\n").replace(b"\r", b"\n")

    # Handle iCal line folding (RFC 5545): lines beginning with SPACE or TAB are continuations
    unfolded_lines = []
    current_line = b""

    for line in txt.split(b"\n"):
        if line.startswith(b" ") or line.startswith(b"\t"):
            # Continuation line - remove leading whitespace and append to current line
            current_line += line[1:]
        else:
            # New property line
            if current_line:
                unfolded_lines.append(current_line)
            current_line = line

    # Don't forget the last line
    if current_line:
        unfolded_lines.append(current_line)

    # Now filter out problematic lines
    sanitized_lines = []
    for line in unfolded_lines:
        if not line.strip():
            continue
        # Skip lines where the property name is just digits
        if b":" in line:
            prop = line.split(b":", 1)[0].strip()
            if prop.isdigit():
                continue
        sanitized_lines.append(line)

    return b"\n".join(sanitized_lines)


# ---------- Google Calendar ----------
# ---------- GitHub PRs ----------
def github_prs(start_date, end_date):
    token = env_required("GITHUB_TOKEN")
    repos = os.getenv("GITHUB_REPOS", "").split(",")
    user = os.getenv("GITHUB_USER")

    if not token:
        return []

    headers = {"Authorization": f"token {token}"}
    prs = []

    for repo in repos:
        repo = repo.strip()
        if not repo:
            continue

        try:
            # First try to get repository info to check access
            repo_info_url = f"https://api.github.com/repos/{repo}"
            repo_check = requests.get(repo_info_url, headers=headers, timeout=30)

            if repo_check.status_code == 404:
                print(f"[aviso] Reposit√≥rio {repo} n√£o encontrado")
                continue
            elif repo_check.status_code != 200:
                print(f"[aviso] Erro ao acessar {repo}: {repo_check.status_code}")
                continue

            # Search for PRs in the repository (simplified search)
            search_query = (
                f"repo:{repo} type:pr updated:>={start_date.strftime('%Y-%m-%d')}"
            )

            url = f"https://api.github.com/search/issues?q={quote(search_query)}"
            response = requests.get(url, headers=headers, timeout=30)

            if response.status_code == 200:
                data = response.json()
                for item in data.get("items", []):
                    prs.append(
                        {
                            "title": item.get("title", ""),
                            "url": item.get("html_url", ""),
                            "state": item.get("state", ""),
                            "repo": repo,
                        }
                    )
            else:
                print(
                    f"[aviso] GitHub API erro {response.status_code} para {repo}: {response.text[:200]}"
                )

        except Exception as e:
            print(f"[aviso] GitHub falhou para {repo}: {e}")

    return prs


# ---------- Jira Issues ----------
def jira_issues(start_date, end_date):
    base_url = env_required("JIRA_BASE_URL")
    email = env_required("JIRA_EMAIL")
    token = env_required("JIRA_TOKEN")

    if not all([base_url, email, token]):
        return []

    import base64

    auth_string = base64.b64encode(f"{email}:{token}".encode()).decode()
    headers = {
        "Authorization": f"Basic {auth_string}",
        "Content-Type": "application/json",
    }

    # JQL query for issues updated in the date range (remove updatedBy filter as it's not available)
    jql = f"updated >= '{start_date.strftime('%Y-%m-%d')}' AND updated <= '{end_date.strftime('%Y-%m-%d')}' ORDER BY updated DESC"

    try:
        url = f"{base_url}/rest/api/3/search"
        params = {"jql": jql, "fields": "summary,status,key,updated", "maxResults": 50}

        response = requests.get(url, headers=headers, params=params, timeout=30)

        if response.status_code == 200:
            data = response.json()
            issues = []
            for issue in data.get("issues", []):
                issues.append(
                    {
                        "key": issue.get("key", ""),
                        "summary": issue.get("fields", {}).get("summary", ""),
                        "status": issue.get("fields", {})
                        .get("status", {})
                        .get("name", ""),
                        "updated": issue.get("fields", {}).get("updated", ""),
                    }
                )
            return issues
        else:
            print(
                f"[aviso] Jira API erro {response.status_code}: {response.text[:200]}"
            )

    except Exception as e:
        print(f"[aviso] Jira falhou: {e}")

    return []


def gcal_events(START, END):
    import datetime as _dt
    import os
    from zoneinfo import ZoneInfo as _ZI

    import requests
    from dateutil.rrule import rrulestr
    from icalendar import Calendar

    tz = TZ
    ics_src = os.getenv("GCAL_ICS_URL")
    token = os.getenv("GOOGLE_CALENDAR_TOKEN")

    # Use the global _sanitize_ics function defined above

    def _norm(dtv):
        if isinstance(dtv, _dt.date) and not isinstance(dtv, _dt.datetime):
            return _dt.datetime.combine(dtv, _dt.time.min).replace(tzinfo=tz)
        if isinstance(dtv, _dt.datetime):
            if dtv.tzinfo is None:
                return dtv.replace(tzinfo=_ZI("UTC")).astimezone(tz)
            return dtv.astimezone(tz)
        return None

    def _parse_ics(raw: bytes):
        # Inline sanitization with proper line folding support
        txt = raw.replace(b"\r\n", b"\n").replace(b"\r", b"\n")
        unfolded_lines = []
        current_line = b""

        for line in txt.split(b"\n"):
            if line.startswith(b" ") or line.startswith(b"\t"):
                current_line += line[1:]
            else:
                if current_line:
                    unfolded_lines.append(current_line)
                current_line = line

        if current_line:
            unfolded_lines.append(current_line)

        sanitized_lines = []
        for line in unfolded_lines:
            if not line.strip():
                continue
            if b":" in line:
                prop = line.split(b":", 1)[0].strip()
                if prop.isdigit():
                    continue
            sanitized_lines.append(line)

        raw = b"\n".join(sanitized_lines)
        cal = Calendar.from_ical(raw)
        events = []
        for comp in cal.walk("vevent"):
            title = str(comp.get("summary") or "(sem t√≠tulo)")
            ds, de, rr = comp.get("dtstart"), comp.get("dtend"), comp.get("rrule")
            if not ds:
                continue
            s1 = _norm(ds.dt)
            e1 = _norm(de.dt) if de else (s1 + _dt.timedelta(hours=1) if s1 else None)
            if not (s1 and e1):
                continue

            if not rr:  # non-recurring
                if s1 <= END and e1 >= START:
                    events.append(
                        {"title": title, "start": s1.isoformat(), "end": e1.isoformat()}
                    )
                continue

            # recurring
            parts = []
            for k, v in rr.items():
                vals = []
                for it in v:
                    if isinstance(it, bytes):
                        it = it.decode("utf-8", "ignore")
                    vals.append(str(it))
                parts.append(f"{k}=" + ",".join(vals))
            rrule_str = ";".join(parts)
            dtstart_utc = s1.astimezone(_ZI("UTC")).strftime("%Y%m%dT%H%M%SZ")
            rule = rrulestr(f"DTSTART:{dtstart_utc}\nRRULE:{rrule_str}", forceset=True)

            w0 = START.astimezone(_ZI("UTC"))
            w1 = END.astimezone(_ZI("UTC"))
            for occ in rule.between(w0, w1, inc=True):
                occ_local = (
                    occ.astimezone(tz)
                    if occ.tzinfo
                    else occ.replace(tzinfo=_ZI("UTC")).astimezone(tz)
                )
                dur = e1 - s1
                oe = occ_local + dur
                if occ_local <= END and oe >= START:
                    events.append(
                        {
                            "title": title,
                            "start": occ_local.isoformat(),
                            "end": oe.isoformat(),
                        }
                    )
        events.sort(key=lambda x: x["start"])
        return events

    # 1) ICS (URL or file)
    if ics_src:
        try:
            if ics_src.startswith(("http://", "https://")):
                resp = requests.get(ics_src, timeout=30, allow_redirects=True)
                ct = resp.headers.get("Content-Type", "")
                if not resp.ok:
                    print(f"[aviso] iCal HTTP {resp.status_code}: {resp.text[:200]}")
                elif "text/calendar" not in ct.lower():
                    print(
                        f"[aviso] iCal content-type inesperado: {ct}. Trecho: {resp.text[:160]!r}"
                    )
                else:
                    return _parse_ics(resp.content)
            else:
                with open(ics_src, "rb") as f:
                    raw = f.read()
                return _parse_ics(raw)
        except Exception as e:
            print(
                f"[aviso] iCal falhou ({type(e).__name__}: {e}); tentando API se houver token..."
            )

    # 2) Fallback: Calendar API
    if not token:
        print(
            "[aviso] Sem GCAL_ICS_URL v√°lido e sem GOOGLE_CALENDAR_TOKEN; pulando Google Calendar."
        )
        return []
    headers = {"Authorization": f"Bearer {token}"}
    params = {
        "timeMin": to_iso_z(START),
        "timeMax": to_iso_z(END),
        "singleEvents": "true",
        "orderBy": "startTime",
    }
    r = requests.get(
        "https://www.googleapis.com/calendar/v3/calendars/primary/events",
        headers=headers,
        params=params,
        timeout=30,
    )
    if not r.ok:
        print(f"[aviso] Google Calendar API erro {r.status_code}: {r.text[:200]}")
        return []
    out = []
    for ev in r.json().get("items", []):
        title = ev.get("summary") or "(sem t√≠tulo)"
        start_dt = ev.get("start", {}).get("dateTime") or ev.get("start", {}).get(
            "date"
        )
        end_dt = ev.get("end", {}).get("dateTime") or ev.get("end", {}).get("date")
        out.append({"title": title, "start": start_dt, "end": end_dt})
    return out


# ---------- Main ----------
if __name__ == "__main__":
    import sys  # ensure this is imported at top if not already

    ap = argparse.ArgumentParser()
    ap.add_argument("--date", help="YYYY-MM-DD")
    ap.add_argument(
        "--slack-dump",
        dest="slack_dump",
        action="store_true",
        help="Print Slack user map and exit",
    )
    args = ap.parse_args()

    # use underscore, not hyphen:
    if args.slack_dump:
        sys.exit(slack_dump())

    # date handling
    if args.date:
        report_day = dt.date.fromisoformat(args.date)
    else:
        report_day = dt.datetime.now(TZ).date()

    START = dt.datetime.combine(report_day, dt.time.min).replace(tzinfo=TZ)
    END = dt.datetime.combine(report_day, dt.time.max).replace(tzinfo=TZ)

    lines = [f"üìå Resumo do dia ‚Äî {report_day}\n"]

    # GitHub PRs
    prs = github_prs(report_day, report_day)
    lines.append(h2("GitHub PRs"))
    if prs:
        for pr in prs:
            lines.append(
                f"- [{pr['repo']}] {pr['title']} ({pr['state']}) - {pr['url']}"
            )
    else:
        lines.append("- (nenhum PR)")

    # Jira Issues
    issues = jira_issues(report_day, report_day)
    lines.append(h2("Jira Issues"))
    if issues:
        for issue in issues:
            lines.append(f"- {issue['key']}: {issue['summary']} ({issue['status']})")
    else:
        lines.append("- (nenhuma issue)")

    # Calendar
    evs = gcal_events(START, END)
    lines.append(h2("Google Calendar"))
    if evs:
        for e in evs:
            lines.append(f"- {e['title']} ({e['start']} ‚Üí {e['end']})")
    else:
        lines.append("- (nenhum evento)")

    # Slack
    hud = slack_dm_huddles(START, END)
    lines.append(h2("Slack Huddles"))
    if hud:
        for h in hud:
            lines.append(f"- {h['text']}")
    else:
        lines.append("- (nenhum huddle)")

    # Write to file
    output_file = os.getenv("OUTPUT_FILE", f"daily_report_{report_day}.txt")

    output_content = "\n".join(lines)
    print(output_content)

    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(output_content)
        print(f"\n‚úÖ Relat√≥rio salvo em: {output_file}")
    except Exception as e:
        print(f"\n‚ö†Ô∏è  Erro ao salvar arquivo: {e}")
